---
title: "Zadanie"
author: "Bartosz Czyż"
date: today
format: 
  html:
    self-contained: true
    toc: true
    toc-depth: 4
    toc-location: right
    toc-title: "Spis treści"
    number-sections: true
    number-depth: 4
    code-fold: show
    code-summary: "Show the code"
    code-tools: true
    code-block-bg: true
    code-block-border-left: "black"
    code-line-numbers: false
    code-copy: true
    smooth-scroll: true
    anchor-sections: true
    link-external-icon: true
    link-external-newwindow: true
    theme:
        light: cosmo
        dark: darkly
    fontsize: 1.0em
    linestretch: 1.5
    fig-align: center
    fig-height: 10
    fig-width: 8
    mermaid-format: svg
editor: 
  markdown: 
    wrap: 72
execute:
  warning: false
  echo: true
  error: false
  cache: false
editor_options: 
  chunk_output_type: console
---

## Load packages

```{r}
library(tidymodels)
library(tidyverse)
library(stringr)
library(vip)
library(pdp)
library(DALEX)
library(DALEXtra)
library(bestNormalize)
library(rules)
library(baguette)
library(finetune)
library(doParallel)
library(skimr)
library(janitor)
library(corrplot)
library(naniar)
library(glmnet)
library(glmnet)
library(kernlab)
library(kknn)
library(ranger)
library(xgboost)
library(gt)

tidymodels_prefer()
```

## Read

```{r}
house_data <- read_csv("train.csv") |>
  clean_names() |>
  mutate(id = as.character(id))

miss_var_summary(house_data)

# Remove columns with too many missing values
house_data <- house_data |>
  select(-c(pool_qc, misc_feature, alley, fence, fireplace_qu,
            utilities, street, land_slope, roof_matl, heating,
            electrical, functional)) |>
  mutate(across(where(is.character), as.factor)) |>
  mutate(ms_sub_class = as.factor(ms_sub_class)) |>
  mutate(across(where(is.factor), ~fct_explicit_na(., na_level = "Missing"))) |>
  select(!where(~is.factor(.) && n_distinct(.) == 1))

house_data |> summary()
glimpse(house_data)
skim(house_data)
```

## Data Exploration

```{r}
# Target variable distribution
p1 <- ggplot(house_data, aes(x = sale_price)) +
  geom_histogram(fill = "blue", alpha = 0.6, bins = 30) +
  labs(title = "Distribution of Sale Prices")

p2 <- ggplot(house_data, aes(x = log(sale_price))) +
  geom_histogram(fill = "red", alpha = 0.6, bins = 30) +
  labs(title = "Distribution of Log-Transformed Sale Prices")

gridExtra::grid.arrange(p1, p2, ncol = 2)

# Correlation matrix for numeric variables
numeric_vars <- house_data |>
  select(where(is.numeric)) |>
  cor(use = "complete.obs")
corrplot(numeric_vars, method = "circle", type = "upper", tl.cex = 0.6)

# Missing values analysis
missing_summary <- house_data |>
  summarise(across(everything(), ~sum(is.na(.)))) |>
  pivot_longer(everything(), names_to = "variable", values_to = "missing_count") |>
  filter(missing_count > 0) |>
  arrange(desc(missing_count))

ggplot(missing_summary, aes(x = reorder(variable, -missing_count), y = missing_count)) +
  geom_col(fill = "red", alpha = 0.6) +
  coord_flip() +
  labs(title = "Variables with Missing Values", x = "Variable", y = "Missing Count")
```

## Data splitting

```{r}
set.seed(123)
house_split <- initial_split(house_data, strata = sale_price, prop = 0.8)
house_train <- training(house_split)
house_test  <- testing(house_split)

house_folds <- vfold_cv(house_train, strata = sale_price, v = 5, repeats = 3)
```

## Recipe Definitions

```{r}
# Basic recipe for linear models, SVM, KNN, etc.
basic_rec <- recipe(sale_price ~ ., data = house_train) |>
  update_role(id, new_role = "ID") |>
  step_rm(id) |>
  step_mutate(ms_sub_class = as.factor(ms_sub_class)) |>
  step_novel(all_nominal_predictors()) |>
  step_unknown(all_nominal_predictors()) |>
  step_impute_knn(all_numeric_predictors()) |>
  step_log(sale_price, offset = 1) |>
  step_nzv(all_predictors()) |>
  step_dummy(all_nominal_predictors()) |>
  # Add this step to remove zero-variance columns after dummy coding
  step_zv(all_predictors()) |>
  step_normalize(all_numeric_predictors())
```

## Model definitions

```{r}
# 1. Linear model with regularization
lm_spec <- linear_reg(penalty = tune(), mixture = tune()) |>
  set_engine("glmnet")

# 2. Random Forest
rf_spec <- rand_forest(
  mtry = tune(),
  trees = tune(),
  min_n = tune()
) |>
  set_engine("ranger") |>
  set_mode("regression")

# 3. XGBoost
xgb_spec <- boost_tree(
  tree_depth = tune(),
  learn_rate = tune(),
  loss_reduction = tune(),
  min_n = tune(),
  sample_size = tune(),
  trees = tune()
) |>
  set_engine("xgboost") |>
  set_mode("regression")

# 4. Support Vector Machine
svm_spec <- svm_rbf(
  cost = tune(),
  rbf_sigma = tune()
) |>
  set_engine("kernlab") |>
  set_mode("regression")

# 5. K-Nearest Neighbors
knn_spec <- nearest_neighbor(
  neighbors = tune(),
  weight_func = tune(),
  dist_power = tune()
) |>
  set_engine("kknn") |>
  set_mode("regression")
```

## Workflow set

```{r}
# Create workflow set with appropriate combinations
house_wfs <- workflow_set(
  preproc = list(
    basic = basic_rec
  ),
  models = list(
    lm = lm_spec,
    rf = rf_spec,
    xgb = xgb_spec,
    svm = svm_spec,
    knn = knn_spec
  ),
  cross = TRUE
)

house_wfs
```

## Tunning Setup

```{r}
house_wfs$wflow_id

# Set up parallel processing
cores <- parallel::detectCores(logical = FALSE) - 1
cl <- makePSOCKcluster(cores)
registerDoParallel(cl)

# Control for racing
race_ctrl <- control_race(
  save_pred = TRUE,
  parallel_over = "everything",
  save_workflow = FALSE
)
```

## Model tuning

```{r}
## Tune models
# set.seed(456)
# time <- Sys.time()

#tune_results <- house_wfs |>
#  workflow_map(
#    "tune_race_anova",
#    seed = 1503,
#    resamples = house_folds,
#    grid = 15,  # Reduced for demonstration
#    control = race_ctrl,
#    verbose = TRUE,
#    metrics = metric_set(rmse, mae, rsq)
#  )

#stopCluster(cl)
#Sys.time() - time

#save(tune_results, file = "house_tune_results.Rdata")
```

## Result Analysis

```{r}
load("house_tune_results.Rdata")

# Check which models worked
tune_results |>
  rank_results(select_best = TRUE) |>
  filter(.metric == "rmse") |>
  select(wflow_id, mean, std_err, model, preprocessor) |>
  knitr::kable()

# Visualization of results
autoplot(tune_results, select_best = TRUE, metric = "rmse") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

# Collect best models
best_results <- tune_results |>
  rank_results(select_best = TRUE) |>
  filter(.metric == "rmse") |>
  group_by(wflow_id) |>
  slice(1) |>
  ungroup()

metrics <- metric_set(rmse, rsq, mae)

best_models <- list()
for (i in 1:nrow(best_results)) {
  workflow_id <- best_results$wflow_id[i]
  config <- best_results$.config[i]
  
  best_models[[workflow_id]] <- tune_results |>
    extract_workflow(id = workflow_id) |>
    finalize_workflow(select_best(
      extract_workflow_set_result(tune_results, id = workflow_id),
      metric = "rmse"
    )) |>
    last_fit(split = house_split, metrics = metrics) 
}
save(best_models, file = "best_models.Rdata")
```

## Final Evaluation

```{r}
# Collect metrics
final_metrics <- best_models |>
  map_dfr(~collect_metrics(.x), .id = "wflow_id") |>
  filter(.metric == "rmse") |>
  arrange(.estimate)

final_metrics |>
  knitr::kable()

# Variable importance for top models
top_models <- final_metrics |>
  slice(1:3) |>
  pull(wflow_id)

for (model in top_models) {
  if (model %in% names(best_models)) {
    workflow <- extract_workflow(best_models[[model]])
    fit <- extract_fit_parsnip(workflow)
    
    if ("ranger" %in% class(fit$fit) | "xgb.Booster" %in% class(fit$fit)) {
      p <- vip(fit) + 
        ggtitle(paste("Variable Importance -", model))
      print(p)
    }
  }
}

# Final predictions comparison
all_predictions <- best_models |>
  map_dfr(~collect_predictions(.x), .id = "wflow_id") |>
  left_join(final_metrics |> select(wflow_id, rmse = .estimate), by = "wflow_id") |>
  mutate(wflow_id = fct_reorder(wflow_id, rmse))

ggplot(all_predictions, aes(x = sale_price, y = .pred, color = wflow_id)) +
  geom_point(alpha = 0.4) +
  geom_abline(intercept = 0, slope = 1, color = "black") +
  facet_wrap(~wflow_id, scales = "free") +
  labs(title = "Actual vs Predicted Sale Prices by Model",
       x = "Actual Price (log)",
       y = "Predicted Price (log)") +
  theme_minimal() +
  theme(legend.position = "none")

# Model performance comparison
performance_plot <- final_metrics |>
  mutate(wflow_id = fct_reorder(wflow_id, .estimate)) |>
  ggplot(aes(x = wflow_id, y = .estimate, fill = wflow_id)) +
  geom_col() +
  coord_flip() +
  labs(title = "Model Performance Comparison (RMSE)",
       x = "Model",
       y = "RMSE") +
  theme_minimal() +
  theme(legend.position = "none")

performance_plot
```

```{r}
load("best_models.Rdata")
best_results <- tune_results |>
  split(~wflow_id) |>
  map(\(x) extract_workflow_set_result(x, id = x$wflow_id) |> select_best(metric = "rmse"))

test_metrics <- best_models |> 
  map_dfr(~collect_metrics(.x), .id = "mod") |> 
  select(mod, .metric, .estimate) |> 
  rename(test = .estimate)

validation_metrics <- tune_results |> 
  rank_results(select_best = TRUE) |> 
  select(wflow_id, .metric, mean) |> 
  rename(mod = wflow_id, validation = mean)

por_test_valid <- test_metrics |>
  full_join(validation_metrics, by = c("mod", ".metric")) |>
  filter(!(is.na(test) & is.na(validation))) |>
  pivot_wider(
    names_from = .metric, 
    values_from = c(test, validation)
  )

por_test_valid |> gt() |> 
  gt::tab_header(title = "Porównanie metryk: Test vs Walidacja")

best_models |>
  map_dfr(~collect_metrics(.x), .id = "mod") |>
  ggplot(aes(mod, .estimate, color = mod)) +
  geom_point(size = 3) +
  facet_wrap(~.metric, scales = "free_y") +
  theme_minimal() +
  labs(x = "Model", y = "Wartość metryki", title = "Porównanie modeli")
```

## Plots

```{r}
# Best compact version
best_plot_data <- test_metrics |>
  full_join(validation_metrics, by = c("mod", ".metric")) |>
  filter(.metric %in% c("rmse", "rsq")) |>
  pivot_longer(
    cols = c(test, validation),
    names_to = "dataset",
    values_to = "value"
  )

# Combined bar plot
p_combined <- ggplot(best_plot_data, aes(x = mod, y = value, fill = dataset)) +
  geom_col(position = position_dodge(width = 0.8), width = 0.7) +
  facet_wrap(~ .metric, scales = "free_y", 
             labeller = as_labeller(c(rmse = "RMSE", rsq = "R²"))) +
  labs(
    title = "Porównanie metryk RMSE i R²: Test vs Walidacja",
    x = "Model",
    y = "Wartość metryki",
    fill = "Zbiór danych"
  ) +
  theme_bw() +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1),
    legend.position = "top"
  ) +
  scale_fill_manual(values = c("validation" = "#E41A1C", "test" = "#377EB8"))

print(p_combined)

# Difference plot
diff_plot <- best_plot_data |>
  pivot_wider(names_from = dataset, values_from = value) |>
  mutate(difference = test - validation) |>
  ggplot(aes(x = mod, y = difference, fill = difference > 0)) +
  geom_col() +
  facet_wrap(~ .metric, scales = "free_y") +
  labs(
    title = "Różnica między testem a walidacją (Test - Walidacja)",
    x = "Model",
    y = "Różnica",
    fill = "Test > Walidacja"
  ) +
  theme_bw() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  scale_fill_manual(values = c("TRUE" = "red", "FALSE" = "blue")) +
  geom_hline(yintercept = 0, linetype = "dashed")

print(diff_plot)
```
